{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Likelihood Analysis with fermipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The python likelihood tools are a very powerful set of analysis tools that expand upon the command line tools provided with the Fermi Science Tools package. Not only can you perform all of the same likelihood analysis with the python tools that you can with the standard command line tools but you can directly access all of the model parameters. You can more easily script a standard analysis. There are also a few things built into the python tools that are not available from the command line like the calculation of upper limits.\n",
    "\n",
    "There are many user contributed packages built upon the python backbone of the Science Tools and this thread will highlight the use of the [fermipy](http://fermipy.readthedocs.org) package.\n",
    "\n",
    "This sample analysis is based on the PG 1553+113 analysis performed by the LAT team and described in [Abdo, A. A. et al. 2010, ApJ, 708, 1310](http://adsabs.harvard.edu/abs/2010ApJ...708.1310A) and closely follows the [Likelihood Analysis with Python](http://fermi.gsfc.nasa.gov/ssc/data/analysis/scitools/python_tutorial.html) thread.  This tutorial assumes you have the most recent ScienceTools installed and [fermipy](http://fermipy.readthedocs.org) installed on top of it.  For instructions on installing fermipy and the Fermi ScienceTools you should consult the [fermipy Installation Instructions](http://fermipy.readthedocs.org/en/latest/install.html).  We will also make significant use of python, so you might want to familiarize yourself with python including matplotlib and other libraries (there's a beginner's guide at http://wiki.python.org/moin/BeginnersGuide). This tutorial also assumes that you've gone through the non-python based [Unbinned Likelihood Tutorial](http://fermi.gsfc.nasa.gov/ssc/data/analysis/scitools/likelihood_tutorial.html).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Get the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "For this thread the original data were extracted from the [LAT data server](http://fermi.gsfc.nasa.gov/cgi-bin/ssc/LAT/LATDataQuery.cgi) with the following selections (these selections are similar to those in the paper):\n",
    "\n",
    "* Search Center (RA,Dec) = (238.929,11.1901)\n",
    "* Radius = 30 degrees\n",
    "* Start Time (MET) = 239557417 seconds (2008-08-04T15:43:37)\n",
    "* Stop Time (MET) = 256970880 seconds (2009-02-22T04:48:00)\n",
    "* Minimum Energy = 100 MeV\n",
    "* Maximum Energy = 300000 MeV\n",
    "\n",
    "Once you exectute the query you can download the data and put it in your working directory.  You'll need to change the names of the files to match the filenames that the data server gave you.  Alternatively you can run with the following tarball which already contains the downloaded files as well as all of the ancillary files that will be generated for the analysis.  In this example the output of the analysis will go into a subdirectory called *pg1553*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "import os\n",
    "if os.path.isfile('../data/pg1553.tar.gz'):\n",
    "    !tar xzf ../data/pg1553.tar.gz\n",
    "else:\n",
    "    !curl -OL https://raw.githubusercontent.com/fermiPy/fermipy-extras/master/data/pg1553.tar.gz\n",
    "    !tar xzf pg1553.tar.gz\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "If you would like to download the raw data files used in this analysis (FT1 and FT2) you can do so by executing the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "import os\n",
    "if os.path.isdir('../data'):\n",
    "    os.environ['DATADIR'] = '../data'\n",
    "else:\n",
    "    !mkdir data\n",
    "    !mkdir data/ft1\n",
    "    !mkdir data/ft2\n",
    "    os.environ['DATADIR'] = 'data'\n",
    "    !curl -o data/ft1/L1504241622054B65347F25_PH00.fits -OL https://raw.githubusercontent.com/fermiPy/fermipy-extras/master/data/ft1/L1504241622054B65347F25_PH00.fits\n",
    "    !curl -o data/ft1/L1504241622054B65347F25_PH01.fits -OL https://raw.githubusercontent.com/fermiPy/fermipy-extras/master/data/ft1/L1504241622054B65347F25_PH01.fits\n",
    "'''\n",
    "    \n",
    "#!curl -o pg1553/L1504241622054B65347F25_PH00.fits http://fermi.gsfc.nasa.gov/ssc/data/analysis/scitools/data/pyLikelihood/L1504241622054B65347F25_PH00.fits\n",
    "#!curl -o pg1553/L1504241622054B65347F25_PH01.fits http://fermi.gsfc.nasa.gov/ssc/data/analysis/scitools/data/pyLikelihood/L1504241622054B65347F25_PH01.fits\n",
    "#!curl -o pg1553/L1504241622054B65347F25_SC00.fits http://fermi.gsfc.nasa.gov/ssc/data/analysis/scitools/data/pyLikelihood/L1504241622054B65347F25_SC00.fits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Make a file list\n",
    "\n",
    "You'll then need to make a file list with the names of your input event files. You can either just make one with a text editor or do the following from the command line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os, glob\n",
    "os.environ['DATADIR']='..'\n",
    "\n",
    "f = open(\"ft1.txt\", \"w+\")\n",
    "#g = open(\"ft2.txt\", \"w+\")\n",
    "\n",
    "for files in glob.glob('*PH[0-9][0-9].fits*'):\n",
    "    f.write(files + '\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Make a config file\n",
    "\n",
    "fermipy bases its analysis on a configuration file (in [yaml](http://yaml.org) format).  We're just going to use a really simple config file for a standard analysis.  There are many many more options which you can use or you can modify these options after the fact within the analysis chain.\n",
    "\n",
    "\n",
    "Make a config file named 'config.yaml' like the following.  For more details on the config file see [config.html](http://fermipy.readthedocs.org/en/latest/config.html).  You will probably need to customize this a bit since your files might not be in the same place or named the same.  The galactic and isotropic diffuse will need to be located on your system (they are included in the science tools or can be downloaded from the FSSC).  In the following example we set the path to these files with the environment variable FERMI_DIFFUSE_DIR.  If FERMI_DIFFUSE_DIR is not defined fermipy will look for the location of these files within the FSSC STs distribution. \n",
    "\n",
    "```\n",
    "data:\n",
    "  evfile : events.txt\n",
    "  scfile : spacecraft.txt\n",
    "\n",
    "binning:\n",
    "  roiwidth   : 10.0\n",
    "  binsz      : 0.1\n",
    "  binsperdec : 8\n",
    "\n",
    "selection :\n",
    "  emin : 100\n",
    "  emax : 300000\n",
    "  zmax    : 90\n",
    "  evclass : 128\n",
    "  evtype  : 3\n",
    "  target : '3FGL J1555.7+1111'\n",
    "\n",
    "gtlike:\n",
    "  edisp : True\n",
    "  irfs : 'P8R2_SOURCE_V6'\n",
    "  edisp_disable : ['isodiff','galdiff']\n",
    "\n",
    "model:\n",
    "  src_roiwidth : 15.0\n",
    "  galdiff  : '$FERMI_DIFFUSE_DIR/gll_iem_v06.fits'\n",
    "  isodiff  : '$FERMI_DIFFUSE_DIR/iso_P8R2_SOURCE_V6_v06.txt'\n",
    "  catalogs : ['3FGL']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Start the analysis\n",
    "\n",
    "Next, you create an analysis script and run the setup steps which include running the selections and generating exposure maps etc.  This will take a bit.\n",
    "\n",
    "This is where the magic happens.  fermipy will load the point source model, create your xml file for you, decide on all the appropriate cuts and binnings and just go.  All of this is configurable from python or from the config file.  And, if you need to rerun things, it's smart enough to not overwrite files if it doesn't need to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Load up some useful modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": true,
    "editable": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Import the GTAnalysis module from fermipy\n",
    "\n",
    "You start by importing the module and then creating an instance of the analysis object from our config file.  When instantiating the analysis object we can override any options defined in the configuration file by passing keyword arguments to the object constructor.  Here we explicitly set the verbosity parameter to 3 (INFO) which supresses DEBUG output.  When we create the object, it spits out a bunch of information about all of the parameters that were used.  You can see there are many more options than the ones we chose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: No names found, cannot describe anything.\n",
      "2022-07-31 02:50:16 INFO    GTAnalysis.__init__(): \n",
      "--------------------------------------------------------------------------------\n",
      "fermipy version v1.1.4 \n",
      "ScienceTools version 2.2.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Prefactor': 0, 'Index1': 1, 'Scale': 2, 'Cutoff': 3, 'Index2': 4}\n",
      "{'Prefactor': 0, 'Index1': 1, 'Scale': 2, 'Cutoff': 3, 'Index2': 4}\n"
     ]
    }
   ],
   "source": [
    "import fermipy\n",
    "from fermipy.gtanalysis import GTAnalysis\n",
    "gta = GTAnalysis('config.yaml',logging={'verbosity': 3})\n",
    "matplotlib.interactive(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### The setup routine\n",
    "\n",
    "This gets everything ready for the likelihood analysis including instantiating the pylikelihood object.  Note that fermipy will skip generating any ancillary files that already exist in the working directory.  In the sample tarball these files have already been produced in order to speed up this stage of the analysis.  If you want to see the behavior of fermipy when running from an empty working directory you can delete one or more of these files before running *setup*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-31 02:51:05 INFO    GTAnalysis.setup(): Running setup.\n",
      "2022-07-31 02:51:05 INFO    GTBinnedAnalysis.setup(): Running setup for component 00\n",
      "2022-07-31 02:51:05 INFO    GTBinnedAnalysis.run_gtapp(): Running gtselect.\n",
      "2022-07-31 02:51:05 INFO    GTBinnedAnalysis.run_gtapp(): time -p gtselect infile=/mnt/c/Users/Julia/Documents/astrophysics-IC/Análise Galáxia de Núcleo Ativo pg1553/evfile_00.txt outfile=/mnt/c/Users/Julia/Documents/astrophysics-IC/Análise Galáxia de Núcleo Ativo pg1553/ft1_00.fits ra=238.9362030029297 dec=11.193900108337402 rad=7.5710678118654755 tmin=239557417.0 tmax=256970880.0 emin=100.0 emax=300000.0 zmin=0.0 zmax=90.0 evclass=128 evtype=3 convtype=-1 phasemin=0.0 phasemax=1.0 evtable=\"EVENTS\" chatter=3 clobber=yes debug=no gui=no mode=\"ql\"\n",
      "2022-07-31 02:51:06 INFO    GTBinnedAnalysis.run_gtapp(): unable to open file \"/mnt/c/Users/Julia/Documents/astrophysics-IC/Análise Galáxia de Núcleo Ativo pg1553/gtselect.par-DESKTOP-7NAKO44-1722\" for writing.\n",
      "2022-07-31 02:51:06 INFO    GTBinnedAnalysis.run_gtapp(): Parameter \"infile\" duplicated on command line.\n",
      "2022-07-31 02:51:06 INFO    GTBinnedAnalysis.run_gtapp(): unable to open file \"/mnt/c/Users/Julia/Documents/astrophysics-IC/Análise Galáxia de Núcleo Ativo pg1553/gtselect.par-DESKTOP-7NAKO44-1722\" for writing.\n",
      "2022-07-31 02:51:06 INFO    GTBinnedAnalysis.run_gtapp(): Parameter \"infile\" duplicated on command line.\n",
      "2022-07-31 02:51:06 INFO    GTBinnedAnalysis.run_gtapp(): Caught N5hoops12ApeExceptionE at the top level: Cannot open parameter file for gtselect; Ape exception code 19 (at /home/conda/feedstock_root/build_artifacts/fermitools_1655479216784/work/src/hoops/src/hoops_ape.cxx: 435)\n",
      "2022-07-31 02:51:06 INFO    GTBinnedAnalysis.run_gtapp(): Finished gtselect. Execution time: 1.04 s\n",
      "2022-07-31 02:51:06 INFO    GTBinnedAnalysis.run_gtapp(): Running gtltcube.\n",
      "2022-07-31 02:51:06 INFO    GTBinnedAnalysis.run_gtapp(): time -p gtltcube evfile=\"/mnt/c/Users/Julia/Documents/astrophysics-IC/Análise Galáxia de Núcleo Ativo pg1553/ft1_00.fits\" evtable=\"EVENTS\" scfile=/mnt/c/Users/Julia/Documents/astrophysics-IC/Análise Galáxia de Núcleo Ativo pg1553/scfile_00.txt sctable=\"SC_DATA\" outfile=/mnt/c/Users/Julia/Documents/astrophysics-IC/Análise Galáxia de Núcleo Ativo pg1553/ltcube_00.fits dcostheta=0.025 binsz=1.0 phibins=0 tmin=0.0 tmax=0.0 file_version=\"1\" zmin=0.0 zmax=90.0 chatter=2 clobber=yes debug=no gui=no mode=\"ql\"\n",
      "2022-07-31 02:51:06 INFO    GTBinnedAnalysis.run_gtapp(): unable to open file \"/mnt/c/Users/Julia/Documents/astrophysics-IC/Análise Galáxia de Núcleo Ativo pg1553/gtltcube.par-DESKTOP-7NAKO44-1727\" for writing.\n",
      "2022-07-31 02:51:06 INFO    GTBinnedAnalysis.run_gtapp(): Parameter \"evfile\" duplicated on command line.\n",
      "2022-07-31 02:51:06 INFO    GTBinnedAnalysis.run_gtapp(): unable to open file \"/mnt/c/Users/Julia/Documents/astrophysics-IC/Análise Galáxia de Núcleo Ativo pg1553/gtltcube.par-DESKTOP-7NAKO44-1727\" for writing.\n",
      "2022-07-31 02:51:06 INFO    GTBinnedAnalysis.run_gtapp(): Parameter \"evfile\" duplicated on command line.\n",
      "2022-07-31 02:51:06 INFO    GTBinnedAnalysis.run_gtapp(): Caught N5hoops12ApeExceptionE at the top level: Cannot open parameter file for gtltcube; Ape exception code 19 (at /home/conda/feedstock_root/build_artifacts/fermitools_1655479216784/work/src/hoops/src/hoops_ape.cxx: 435)\n",
      "2022-07-31 02:51:06 INFO    GTBinnedAnalysis.run_gtapp(): Finished gtltcube. Execution time: 0.76 s\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/fermi/lib/python3.9/site-packages/fermipy/gtanalysis.py:1087\u001b[0m, in \u001b[0;36mGTAnalysis.setup\u001b[0;34m(self, init_sources, overwrite, **kwargs)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;66;03m# Run setup for each component\u001b[39;00m\n\u001b[1;32m   1086\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomponents):\n\u001b[0;32m-> 1087\u001b[0m     \u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1089\u001b[0m \u001b[38;5;66;03m# Create likelihood\u001b[39;00m\n\u001b[1;32m   1090\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_likelihood()\n",
      "File \u001b[0;32m~/anaconda3/envs/fermi/lib/python3.9/site-packages/fermipy/gtanalysis.py:5176\u001b[0m, in \u001b[0;36mGTBinnedAnalysis.setup\u001b[0;34m(self, overwrite, **kwargs)\u001b[0m\n\u001b[1;32m   5173\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_ltcube(overwrite\u001b[38;5;241m=\u001b[39moverwrite, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   5175\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoading LT Cube \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfiles[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mltcube\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m-> 5176\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ltc \u001b[38;5;241m=\u001b[39m \u001b[43mLTCube\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mltcube\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5178\u001b[0m \u001b[38;5;66;03m# Extract tmin, tmax from LT cube\u001b[39;00m\n\u001b[1;32m   5179\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tmin \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ltc\u001b[38;5;241m.\u001b[39mtstart\n",
      "File \u001b[0;32m~/anaconda3/envs/fermi/lib/python3.9/site-packages/fermipy/ltcube.py:192\u001b[0m, in \u001b[0;36mLTCube.create\u001b[0;34m(cls, ltfile)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ltfile, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    190\u001b[0m     files \u001b[38;5;241m=\u001b[39m glob\u001b[38;5;241m.\u001b[39mglob(ltfile)\n\u001b[0;32m--> 192\u001b[0m ltc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_from_fits(\u001b[43mfiles\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m files[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[1;32m    194\u001b[0m     ltc\u001b[38;5;241m.\u001b[39mload_ltfile(f)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "gta.setup(overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Before proceeding with the analysis we'll have a quick look at the files that are produced by the setup function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "ls pg1553/*fits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Here is a brief explanation of the contents of each file and its role in the analysis:\n",
    "\n",
    "* **ft1_00.fits**: Event list.  This is generated by running gtselect and gtmktime on our input file list.\n",
    "* **bexpmap_00.fits**: All-sky binned exposure map.  This map is interpolated to create an exposure model when generating the srcmap file.\n",
    "* **bexpmap_roi_00.fits**: Binned exposure map for the ROI.  This file is only provided for visualization purposes in order to have an exposure map with the same binning as the data and model maps.\n",
    "* **ccube_00.fits**: Counts cube for the ROI.\n",
    "* **ltcube_00.fits**: Livetime cube.  This contains a map of the livetime for this observation over the whole sky as a function of incidence angle.\n",
    "* **srcmap_00.fits**: Source map cube.  This file contains maps for each of the components in the ROI after convolution with exposure and the PSF.  Note that energy dispersion is applied at run-time.\n",
    "\n",
    "Note that all of the files have a numerical suffix '00'.  This is the analysis component index.  In a multi-component analysis there would be instances of all of the above files for each analysis component.  The files with no component index are co-added maps that are provided for visualization purposes.\n",
    "\n",
    "To see example of one of these files we can open and plot the counts cube file.  This is a 3D cube that contains the distribution of events as a function of energy and two spatial coordinates.  In the example below we sum over the energy dimension of the cube to make a 2-D sky image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import astropy.io.fits as pyfits\n",
    "\n",
    "h = pyfits.open('pg1553/ccube.fits')\n",
    "h.info()\n",
    "counts = h[0].data\n",
    "counts.shape\n",
    "plt.figure()\n",
    "plt.imshow(np.sum(counts,axis=0),interpolation='nearest',origin='lower')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We can now inspect the state of the ROI prior with the print_roi() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "gta.print_roi()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Additional details about an individual source can be retrieved by printing the corresponding source object.  Here we use the bracket operator to return the properties of PG1553. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(gta.roi['3FGL J1555.7+1111'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Do the likelihood fitting\n",
    "\n",
    "Now that all of the ancillary files have been generated, we can move on to the actual fitting.  The first thing you should do is free some of the sources since all of the sources are initially fixed.  We'll just free those sources in the center region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Free Normalization of all Sources within 3 deg of ROI center\n",
    "gta.free_sources(distance=3.0,pars='norm')\n",
    "\n",
    "# Free all parameters of isotropic and galactic diffuse components\n",
    "gta.free_source('galdiff')\n",
    "gta.free_source('isodiff')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In this simple anlaysis we are leaving the spectral shapes of sources fixed but we're going to free the spectral shape of the source we care about.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "gta.free_source('3FGL J1555.7+1111')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now, actually do the fit.  The software does its best to get the fit to converge by running the fit several times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "fit_results = gta.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The dictionary returned by the fit method returns a variety of diagnostic information about the fit including the fit quality, the relative improvement in the likelihood, and the correlations among the fit parameters.  We can inspect the results of the fit by printing the source object for PG1553."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print('Fit Quality: ',fit_results['fit_quality'])\n",
    "print(gta.roi['3FGL J1555.7+1111'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "You can then save the state of the roi to an output file for reference later.  The write_roi function does this.  The first argument is a string that will be prepended to the names of the output files generated by this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "gta.write_roi('fit0',make_plots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "There are a lot of diagnostic plots also saved at the same time.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "ls -l pg1553/*.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "pngs = glob('pg1553/*.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "for png in pngs:\n",
    "    my_image = Image(png)\n",
    "    display(my_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Reading in the results\n",
    "\n",
    "Since the results are saved, you can load them back up at any point (you can also get to these within python).  Here we retrieve the analysis results from the output numpy file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "c = np.load('pg1553/fit0.npy').flat[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The `sources` dictionary has an entry for each source in the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "sorted(c['sources'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's take a look at the flux, spectral parameters, and TS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "c['sources']['3FGL J1555.7+1111']['flux']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(c['sources']['3FGL J1555.7+1111']['param_names'][:4])\n",
    "print(c['sources']['3FGL J1555.7+1111']['param_values'][:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "c['sources']['3FGL J1555.7+1111']['ts']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The SED is in there as well.  We can plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "E = np.array(c['sources']['3FGL J1555.7+1111']['model_flux']['energies'])\n",
    "dnde = np.array(c['sources']['3FGL J1555.7+1111']['model_flux']['dnde'])\n",
    "dnde_hi = np.array(c['sources']['3FGL J1555.7+1111']['model_flux']['dnde_hi'])\n",
    "dnde_lo = np.array(c['sources']['3FGL J1555.7+1111']['model_flux']['dnde_lo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.loglog(E, (E**2)*dnde, 'k--')\n",
    "plt.loglog(E, (E**2)*dnde_hi, 'k')\n",
    "plt.loglog(E, (E**2)*dnde_lo, 'k')\n",
    "plt.xlabel('E [MeV]')\n",
    "plt.ylabel(r'E$^2$ dN/dE [MeV cm$^{-2}$ s$^{-1}$]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "If you want SED points, there's a function for that.  There are lots of options for this which you can set in the config file or from keyword arguments of the function itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "sed = gta.sed('3FGL J1555.7+1111')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "You can save the state to the yaml file or you can just access it directly.  This is also the way to get at the dictionary for any individual source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "src = gta.roi['3FGL J1555.7+1111']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.loglog(E, (E**2)*dnde, 'k--')\n",
    "plt.loglog(E, (E**2)*dnde_hi, 'k')\n",
    "plt.loglog(E, (E**2)*dnde_lo, 'k')\n",
    "plt.errorbar(np.array(sed['e_ctr']),\n",
    "             sed['e2dnde'], \n",
    "             yerr=sed['e2dnde_err'], fmt ='o')\n",
    "plt.xlabel('E [MeV]')\n",
    "plt.ylabel(r'E$^{2}$ dN/dE [MeV cm$^{-2}$ s$^{-1}$]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Looks like those last two points should be upper limits.  Let's plot those instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.loglog(E, (E**2)*dnde, 'k--')\n",
    "plt.loglog(E, (E**2)*dnde_hi, 'k')\n",
    "plt.loglog(E, (E**2)*dnde_lo, 'k')\n",
    "plt.errorbar(sed['e_ctr'][:-2],\n",
    "             sed['e2dnde'][:-2], \n",
    "             yerr=sed['e2dnde_err'][:-2], fmt ='o')\n",
    "plt.errorbar(np.array(sed['e_ctr'][-2:]),\n",
    "         sed['e2dnde_ul95'][-2:], yerr=0.2*sed['e2dnde_ul95'][-2:], \n",
    "             fmt='o', uplims=True)\n",
    "plt.xlabel('E [MeV]')\n",
    "plt.ylabel(r'E$^{2}$ dN/dE [MeV cm$^{-2}$ s$^{-1}$]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Summary\n",
    "\n",
    "There is a lot of other functionality and you should look through the docs for more details.  You can also inspect the GTAnalysis object for some of these (like TS Maps, extension tests, and using event types).  Following threads cover some of the more advanced functionality of fermipy:\n",
    "\n",
    "* [IC443](ic443.ipynb) : Analysis to measure the angular extension of the SNR IC443.\n",
    "* [Draco](draco.ipynb) : DM upper limit analysis of the Draco dwarf spheroidal galaxy."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "fermi-env",
   "language": "python",
   "name": "fermi-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
